+++
title = "H4 - Enumeration with ffuf"
date = "2025-09-15"
categories = ["pentesting-course"]
+++

---

### a) Dirfuz-1

I got the target binary from [(Tero Karvinen Find Hidden Web Directories - Fuzz URLs with ffuf.)](https://terokarvinen.com/2024/fuzz-urls-find-hidden-directories/) and `chmod u+x dirfuzt-1` to make it runnable. I also got the seclists by `sudo apt install seclists`. After which I disconnected
my virtual machine from the internet. We are tasked to find two URLs: Admin page and a Version Control related page.

![Challenge](/tuukkaani-blog/img/h4/challenge.png)

After running the random binary `./dirfuzt-1` I found on the internet and whose creator told me to do so, I got the front page up.

![Trust me bro](/tuukkaani-blog/img/h4/dirfuzt.png)

My first though was to just try running ffuf as follows: `ffuf -u http://127.0.0.2:8000/FUZZ -w /usr/share/seclists/Discovery/Web-Content/common.txt -mc 200`. After doing so I got a huge list of pages with similar stats.

![Ffuf results](/tuukkaani-blog/img/h4/fuff.png)

And if we go to one of these pages, for example /zips, we can see it is the same as the index page.

![Nothing, again](/tuukkaani-blog/img/h4/zips.png)

Now I assume most of the pages that returned with 200 are the same page, so I need to do some additional filtering.
I decide to filter by word count. In the [Ffuf man pages](https://manpages.debian.org/testing/ffuf/ffuf.1.en.html) I found flag for filtering by word count. I ran the previous command again now with the new additional `-fw 9` flag and got the following results.

![Filtered results](/tuukkaani-blog/img/h4/newffuf.png)

It seems ffuf found pages that related to the task at hand, going to the /wp-admin page gives us our first flag.

![First flag](/tuukkaani-blog/img/h4/firstflag.png)

The second flag can be found on any of the /.git pages.

![Second flag](/tuukkaani-blog/img/h4/secondflag.png)

And so the challenge is done. In the end we found the flags by running the following command `ffuf -u http://127.0.0.2:8000/FUZZ -w /usr/share/seclists/Discovery/Web-Content/common.txt -mc 200 -fw 9`. So in short, we dug through the target URL for 
using `-w /your/wordlist/here` wordlist, `-mc 200` to match all pages that return with status 200 and lastly `-fw 9` filter out pages with the word count of 9. Once again, all of this can be found from ffuf's man pages. [(Fuff man page.)](https://manpages.debian.org/testing/ffuf/ffuf.1.en.html)

---

### b) Fuffme

For this section, I'll be following the instructions found at [(Tero Karvinen Fuffme).](https://terokarvinen.com/2023/fuffme-web-fuzzing-target-debian/)
I installed the missing dependencies, in this case docker `sudo apt install docker.io`. After which I followed the
rest of the guide and got the container running successfully.

![Fuffme curl](/tuukkaani-blog/img/h4/ffufme.png)

Next I got the wordlists that were listed in the instructions, disconnected the vm and then I was ready to start doing the
practice exercises.

---

### c) Basic Content Discovery

So the first I needed to do the following:

![Basic fuzz](/tuukkaani-blog/img/h4/basic.png)

And it seems everything is in working order:

![Ffuf output](/tuukkaani-blog/img/h4/basicffuf.png)

---

### d) Content Discovery With Recursion

Again the task goes as follows:

![Recursion task](/tuukkaani-blog/img/h4/recursion.png)

After doing the task, I didn't really like that fact that the output
doesn't show the full URL, but instead lists just the matched word. I did some digging and found a pull request where such flag
was to be added, but joohoi seems to avoid *bloat* so an alternative solution was given by piping to grep [(Ffuf pull request.)](https://github.com/ffuf/ffuf/pull/490). In the end this is the command I ran `ffuf -u http://localhost/cd/recursion/FUZZ -w /usr/share/wordlists/common.txt -recursion -v 2>/dev/null | grep -oE 'http[^ ]*'`.

![Recursion ffuf](/tuukkaani-blog/img/h4/recursionffuf.png)

---

### e) Content Discovery With File Extensions

The task:

![File Extensions](/tuukkaani-blog/img/h4/fileextension.png)

Results by using `ffuf -u http://localhost/cd/ext/logs/FUZZ -w common.txt -e .log`:

![Ffuf results](/tuukkaani-blog/img/h4/extffuf.png)

---

### f) No 404 status

The task:

![no404](/tuukkaani-blog/img/h4/404.png)

Results by using `ffuf -u http://localhost/cd/no404/FUZZ -w common.txt -fs 669`:

![Ffuf results](/tuukkaani-blog/img/h4/404ffuf.png)

---

### g) Param mining

The task:

![Param Mining](/tuukkaani-blog/img/h4/mining.png)

Results by using `ffuf -u http://localhost/cd/param/data?FUZZ=1 -w common.txt`:

![Ffuf results](/tuukkaani-blog/img/h4/miningffuf.png)

---

### h) Rate Limited 

So the following task is:

![Rate Limited](/tuukkaani-blog/img/h4/rate.png)

We are told that the our requests have a 50 requests/second limit.
So we first `ffuf -u http://localhost/cd/rate/FUZZ -w /usr/share/wordlists/common.txt -mc 200,429`:

![Ffuf hitting the limits](/tuukkaani-blog/img/h4/ratefirst.png)

Here we see a bunch of status 429s. This is due to us hitting the limit and getting our driver's license revoked for a couple of seconds. We repeat what we just did, but this time abide by the rate limits to avoid any issues `ffuf -u http://localhost/cd/rate/FUZZ -w /usr/share/wordlists/common.txt -t 5 -p 0.1 -mc 200,429`:

![Ffuf but slower](/tuukkaani-blog/img/h4/ratesecond.png)

Now we got the file we were after, the process also notably took longer to finish.

---

### i) Subdomains - Virtual host Enumeration

Task at hand: 

![Subdomains](/tuukkaani-blog/img/h4/subdomain.png)

We can enumerate the subdomains by using the Host header with ffuf on virtual hosts.
Results by using `ffuf -u http://localhost -H "Host: FUZZ.ffuf.me" -w subdomains.txt -fs 1495`:

![Subdomains ffuf](/tuukkaani-blog/img/h4/subdomainffuf.png)

---

### x) Additional reading

#### Fuzz URLs with ffuf

The page goes over what ffuf is and what it is used for.
After which we are guided through a process of installing sample targets 
and all the required tools and dictionaries for attacking the sample targets.
Lastly you can find some use case examples with useful flags that will be used when 
testing against the given targets. [(Tero Karvinen Find Hidden Web Directories - Fuzz URLs with ffuf).](https://terokarvinen.com/2024/fuzz-urls-find-hidden-directories/)

#### Ffuf readme

The readme page goes over, well, the usage of ffuf including installation, use cases, 
the flags and so on. The readme page's content itself isn't really that interesting, but the readme page as a whole is pretty good. Having practice targets made by other people listed, video examples, concise examples and instructions.
Everything is easy to find and parse through quickly especially compared to some other readme pages 
which can be like opening all of the holy texts in one go. After seeing all the flags listed, I can also understand why 
joohoi might want to limit the amounts of flags added. Keeping everything fast and avoiding unnecessary *bloat*, seems
to be quite high up the priority list. A choice that is hard to dislike for sure :D. [(Hoikkala "joohoi" 2023. Ffuf readme).](https://github.com/ffuf/ffuf/blob/master/README.md) 

---


### Sources

All the assignments this page is based on can be found at [Tero Karvinen](https://terokarvinen.com/tunkeutumistestaus/)

[Tero Karvinen Find Hidden Web Directories - Fuzz URLs with ffuf.](https://terokarvinen.com/2024/fuzz-urls-find-hidden-directories/)

[Tero Karvinen Fuffme.](https://terokarvinen.com/2023/fuffme-web-fuzzing-target-debian/)

[Ffuf pull request.](https://github.com/ffuf/ffuf/pull/490)

[Fuff man page.](https://manpages.debian.org/testing/ffuf/ffuf.1.en.html)

[Hoikkala "joohoi" 2023. Ffuf readme.](https://github.com/ffuf/ffuf/blob/master/README.md) 

